Resilient Capacity-Aware Routing
Stefan Schmid, Nicolas Schnepf, Ji?? Srba
To ensure a high availability, communication networks provide resilient routing mechanisms that quickly change routes upon failures. However, a fundamental algorithmic question underlying such mechanisms is hardly understood: how to verify whether a given network reroutes flows along feasible paths, without violating capacity constraints, for up to k link failures? We chart the algorithmic complexity landscape of resilient routing under link failures, considering shortest path routing based on link weights as e.g. deployed in the ECMP protocol. We study two models: a pessimistic model where flows interfere in a worst-case manner along equal-cost shortest paths, and an optimistic model where flows are routed in a best-case manner, and we present a complete picture of the algorithmic complexities.We further propose a strategic search algorithm that checks only the critical failure scenarios while still providing correctness guarantees. Our experimental evaluation on a benchmark of Internet and datacenter topologies confirms an improved performance of our strategic search by several orders of magnitude.
Routing and traffic engineering are most fundamental tasks in a communication network. Internet Service Providers (ISPs) today use several sophisticated strategies to efficiently provision their backbone network to serve intra-domain traffic. This is challenging as in addition to simply providing reachability, routing protocols should also account for capacity constraints: to meet quality-ofservice guarantees, congestion must be avoided. Intra-domain routing protocols are usually based on shortest paths, and in particular the Equal-Cost-MultiPath (ECMP) protocol [24] . Flows are split at nodes where several outgoing links are on shortest paths to the destination, based on per-flow static hashing [7, 30] . In addition to default routing, most modern communication networks also provide support for resilient routing: upon the detection of a link failure, the network nodes quickly and collaboratively recompute the new shortest paths [21] . However, today, we still do not have a good understanding of the algorithmic complexity of shortest path routing subject to capacity constraints, especially under failures. In particular, in this paper we are interested in the basic question: "Given a capacitated network based on shortest path routing (defined by link weights), can the network tolerate up to k link failures without violating capacity constraints?" Surprisingly only little is known about the complexity aspects. Our Contributions. We provide a complete characterization of the algorithmic complexity landscape of resilient routing and introduce two basic models of how traffic is distributed across the multiple shortest paths. A pessimistic (P) one where flows add up in a worst-case manner; if a network is resilient in the pessimistic model, it is guaranteed that routing succeeds along any shortest path without overloading links. In the optimistic (O) model flows add up in a bestcase manner; if a network is resilient in the optimistic model, it may be that the specific routing does not overload the links. The two models hence cover the two extremes in the spectrum and alternative routing schemes, e.g., (pseudo)random routing hence lies in between. Figure 1 illustrates the situations that can arise in a network: depending on the scenario, pessimistic (P) or optimistic (O), and whether the routing feasibility test is positive or negative, we can distinguish between three regimes. (1) If routing is feasible even in the pessimistic case, then flows can be safely forwarded by any routing policy without violating any capacity constraints. (2) If the pessimistic test is negative but positive in the optimistic case, then further considerations are required to ensure that flows use the feasible paths (e.g., a clever routing algorithm to find the suitable paths is needed). (3) If even the optimistic test is negative then no feasible routing solution exists; to be able to successfully route flows in this case, we need to change the network characteristics, e.g., to increase the link capacities. We further distinguish between splittable (S) and nonsplittable (N) flows, and refer to the four possible problems by PS, PN, ON, and OS. Our main complexity results are summarized in Figure 2 . We can see that without link failures (Figure 2a ), the problems are solvable in polynomial time, except for the ON problem that becomes NP-complete. Moreover, the pessimistic variants of the problem can be solved even in nondeterministic logarithmic space, implying that they allow for efficient parallelization [33] . On the other hand, the optimistic splittable problem is hard for the class P. For the problems with link failures ( Figure 2b ) the complexity increases and the problems become co-NPcomplete, apart from the ON problem that becomes more difficult to solve and is complete for the second level of the polynomial hierarchy [33] . The high computational complexity of the instances with link failures may indicate that a brute-force search algorithm exploring all failure scenarios is needed to verify whether routing is feasible. However, we present a more efficient solution, by defining a partial ordering on the possible failure scenarios with the property that for the pessimistic model, we only need to explore the minimum failure scenarios, and for the optimistic model, it is sufficient to explore the maximum failure scenarios. We present an efficient strategic search algorithm implementing these ideas, formally prove its correctness, and demonstrate the practical applicability of strategic search on a benchmark of Internet and datacenter topologies. In particular, we find that our algorithm achieves up to several orders of magnitude runtime savings compared to the brute-force search. Related Work. Efficient traffic routing has received much attention in the literature, and there also exist empirical studies on the efficiency of ECMP deployments, e.g., in Internet Service Provider Networks [17] or in datacenters [22] . A systematic algorithmic study of routing with ECMP is conducted by Chiesa et al. in [10] . The authors show that in the splittable-flow model [16] , even approximating the optimal link-weight configuration for ECMP within any constant factor is computationally intractable. Before their work, it was only known that minimizing congestion is NP-hard (even to just provide "satisfactory" quality [2] and also under path cardinality constraints [5] ) and cannot be approximated within a factor of 3/2 [19] . For specific topologies the authors further show that traffic engineering with ECMP remains suboptimal and computationally hard for hypercube networks. We significantly extend these insights into the algorithmic complexity of traffic engineering and introduce the concept of pessimistic and optimistic variants of routing feasibility and provide a complete characterization of the complexity of routing subject to capacity constraints, also in scenarios with failures. Accounting for failures is an important aspect in practice [13, 31] but has not been studied rigorously in the literature before; to the best of our knowledge, so far there only exist heuristic solutions [18] with some notable exceptions such as Lancet [8] (which however does not account for congestion). We propose to distinguish between optimistic and pessimistic flow splitting; existing literature typically revolves around the optimistic scenario. We note that while we focus on IP networks (and in particular shortest path routing and ECMP), there exist many interesting results on the verification and reachability testing in other types of networks and protocols, including BGP [4, 15] , MPLS [25, 38] , OpenFlow [1] networks, or stateful networks [29, 32, 41] . While most existing literature focuses on verifying logical properties, such as reachability without considering capacity constraints, there also exist first works dealing with quantitative properties [20, 26, 29 ]. We shall now define the model of network with link capacities and flow demands and formally specify the four variants of the resilient routing problem. Let N be the set of natural numbers and N 0 the set of nonnegative integers. Capacities and Demands (NCD) is a triple N = (V, C, D) where V is a finite set of nodes, C : V ? V ? N 0 is the capacity function for each network edge (capacity 0 implies the absence of a network link), and D : V ? V ? N 0 is the end-to-end flow demand between every pair of nodes such that D(v, v) = 0 for all v ? V (demand 0 means that there is no flow). By Paths(s, t) we denote the set of all paths from s to t. Routes in an NCD are traditionally determined by annotating the links with weights and employing shortest path routing (e.g. ECMP). In case of multiple shortest paths, traffic engineers select either one of the shortest paths or decide to split the flow among the different shortest paths for load-balancing purposes. When one or multiple links fail, the set of shortest paths may change and the routes need to be updated. The weight assignment is usually provided by the network operators and is primarily used for traffic engineering purposes. Assume now a fixed weight assignment for a given NCD N = (V, C, D). Let ð = v 1 v 2 · · · v n ? V + be a path from v 1 to v n . The weight of the path ð is denoted by W (ð) and defined by W (ð) = The set of shortest paths from s to t is defined by SPaths(s, t) = {ð ? Paths(s, t) | W (ð) = ? and W (ð) ? W (ð ) for all ð ? Paths(s, t)}. As the weights are positive, all shortest paths in the set SPaths(s, t) are acyclic and hence the set is finite (though of possibly exponential size). For a given NCD N and a set of failed links F , we can now define the NCD N F where all links from F are removed.  By Paths F (s, t) and SPaths F (s, t) we denote the sets of the paths and shortest paths between s and t in the network We shall now define a flow assignment that for each nonempty flow demand between s and t and every failure scenario, determines the amount of traffic that should be routed through the shortest paths between s and t. A flow assignment f in a capacity network N = (V, C, D) with weight assignment W and with the set 1} for all s, t ? V and all ð ? SPaths F (s, t). Otherwise the flow assignment is splittable. The notation [0, 1] denotes the interval of all rational numbers between 0 and 1 and it determines how the load demand between the nodes s and t is split among the routing paths between the two nodes. A nonsplittable flow assignment assigns the value 1 to exactly one routing path between any two nodes s and t. If for a given failure scenario F there is no path between s and t for two nodes with D(s, t) > 0, then there is no flow assignment as the network is disconnected. For a connected NCD, we now define a feasible flow assignment that avoids congestion: the sum of portions of flow demands (determined by the flow assignment) that are routed through each link, may not exceed the link capacity. We consider four different variants of the capacity problem. Given an NCD N with a weight assignment and nonnegative integer k, is it the case that for every set F of failed links of cardinality at most k, the network remains connected and every splittable/nonsplittable flow assignment on N with the set F of failed links is feasible? A positive answer to the PN capacity problem implies positive answers to both PS and ON problems. A positive answer to either the PS or ON problem implies a positive answer to the OS problem. This is summarized in Figure 3 and it is easy to argue that the hierarchy is strict. We now provide the arguments for the upper and lower bounds from Figure 2 .  Complexity Upper Bounds. We present first a few useful observations. Because network connectivity can be checked independently for each source s and target t where D(s, t) > 0 by computing the maximum flow [14] between s and t, we obtain the following lemma. Next, we present an algorithm that for an NCD N = (V, C, D) with the weight assignment W : V ? V ? N ? {?} and a given pair of nodes s, t ? V computes in polynomial time the function spg s,t : V ? V ? {0, 1} that assigns the value 1 to exactly all edges that appear on at least one shortest path (w.r.t. to the weight assignment W ) between s and t. The edges that get assigned the value 1 hence form the shortest path subgraph between s and t. The algorithm uses the function dist(v, v ) that for every two nodes v, v ? V returns the length of the shortest path (again w.r.t. to the assignment W ) from v to v and if v and v are not connected then it returns ?. Such an all-pairs shortest path function can be precomputed in polynomial time using e.g. the Johnson's algorithms [27] . The function spg s,t is defined by Algorithm 1.  We first present results for k = 0 (no link failures) and start by showing that the optimistic splittable variant of the capacity problem is decidable in polynomial time by reducing it to the feasibility of a linear program. Let N = (V, C, D) be an NCD with weight assignment W and let spg s,t be precomputed for all pairs of s and t. We construct a linear program over the variables x s,t (v, v ) for all s, t, v, v ? V where the variable x s,t (v, v ) represents the percentage of the total demand D(s, t) between s and t that is routed through the link (v, v ). In the equations below, we let s and t range over all nodes that satisfy D(s, t) > 0. Equation 1 imposes that the flow portion on any link must be between 0 and 1. Equation 2 makes sure that portion of the demand D(s, t) must be split along all outgoing links from s that belong to the shortest path graph. Similarly Equation 3 guarantees that the flows on incoming links to t in the shortest path graph deliver the total demand. Equation 4 is a flow preservation equation among all incoming and outgoing links (in the shortest path graph) connected to every node v. The first four equations define all possible splittings of the flow demands for all s and t such that D(s, t) > 0. Finally, Equation 5 checks that for every link in the network, the total sum of the flows for all s-t pairs does not exceed the link capacity. The size of the constructed system is quadratic in the number of nodes and its feasibility, that can be verified in polynomial time [39] , corresponds to the existence of a solution for the OS problem. If we now restrict the variables to nonnegative intergers, we get an instance of integer linear program where feasibility checking is NP-complete [39] , and corresponds to the solution for the nonsplittable optimistic problem. Next, we present a theorem stating that both the splittable and nonsplittable variants of the pessimistic capacity problem are decidable in polynomial time and in fact also in nondeterministic logarithmic space (the complexity class NL). Proof. Let N = (V, C, D) be a given NCD with a weight assignment W . Let us consider the shortest path graph represented by spg s,t as defined by Algorithm 1. Clearly, if the set SPaths(s, t) for some s, t ? V where D(s, t) > 0 is empty, the answer to both the splittable and nonsplittable problem is negative. Otherwise, for each pair s, t ? V where D(s, t) > 0, the entire demand D(s, t) can be routed (both in the splittable and nonsplittable case) through any edge (v, v ) that satisfies spg s,t (v, v ) = 1. Hence we can check whether for every edge ( If this is the case, then the answer to both the splittable and the nonsplittable pessimistic problem is positive as there is no flow assignment that can exceed the capacity of any link. On the other hand, if for some link (v, v ) the sum of all demands that can be possibly routed through (v, v ) exceeds the link capacity, the answer to the problem (both splittable and nonsplittable) is negative. The algorithm can be implemented to run in nondeterministic logarithmic space. Let us now turn our attention to the four variants of the problem under the assumption that up to k links can fail (where k is part of the input to the decision problem). Given an NCD N = (V, C, D) with a weight assignment W , we are asked to check, for all (exponentially many) failure scenarios F ? V ? V where |F | ? k, whether the pruned NCD N F with the weight assignment W F (as defined in Definition 3) satisfies that the network N F is connected and every flow assignment is feasible (in case of the pessimistic case) or there exists a feasible flow assignment (in case of the optimistic case). As these problems are decidable in polynomial time for PN, PS and OS, we can conclude that the variants of the problems with failures belong to the complexity class co-NP: for the negation of the problems we can guess the failure scenario F for which the problem does not have a solution-this can be verified in polynomial time by Theorems 1 and 3. Finally, the same arguments can be used also for the optimistic nonsplittable problem with failures. However, as deciding the ON problem without failures is solvable only in nondeterministic polynomial time, the extra quantification of all failure scenarios means that the problem belongs to the class Ð P 2 on the second level of the polynomial hierarchy [33] . This complexity class is believed to be computationally more difficult than the problems on the first level of the hierarchy (where the NP and co-NP problems belong to). Complexity Lower Bounds. We now prove the complexity lower bounds. Proof sketch. By NC-reduction from the P-complete maximum flow problem for directed acyclic graphs [35] : given a directed acyclic graph G with nonnegative edge capacities, two nodes s and t and a number m, is there a flow between s and t that preserves the capacity of all edges and has the volume of at least m? This problem can be rephrased as our OS problem by setting the demand D(s, t) = m and defining a weight assignment so that every relevant edge in G is on some shortest path from s to t. This can be achieved by topologically sorting the nodes (in NC 2 [11, 12] ) and assigning the weights accordingly. Proof sketch. Follows from NL-hardness of reachability in digraphs [33] . Next, we show that the ON problem is NP-hard, even with no failures. Figure 4a we give an example of the reduction for a given satisfiable formula. As we consider the nonsplittable problem, the flow demand from s 0 to s k means that the whole demand of n units must go through either the link (x i , s i ) or (x i , s i ), for every i. This corresponds to choosing an assignment of the variables to true or false. For every clause c i we now have a unit flow from c s i to c e i that goes through the link ( j , s j ) for every literal j appearing in the clause c i . This is only possible if this link is not already occupied by the flow demand from s 0 to s k ; otherwise we exceed the capacity of the link. For each clause c i we need to find at least one literal j so that the flow can go through the edge ( j , s j ). As the capacity of the edge ( j , s j ) is n, it is possible to use this edge for all n clauses if necessary. We can observe that the capacity network can be constructed in polynomial time and we shall argue for the correctness of the reduction. We can now observe that if ? is satisfiable, we can define a feasible flow assignment f by routing the flow demand of n between s 0 and s k so that it does  Capacity of all links is 4 and weight of links is 1. Double arrows are 2-unbreakable links. For the other direction where ? is not satisfieable, we notice that any routing of the flow demand between s 0 and s k (corresponding to some truth assignment of ?) leaves at least one clause unsatisfied and it is then impossible to route the flow for such a clause without violating the capacity constraints. We now extend the reduction from Theorem 8 to the OS case with link failures and prove its hardness for the second level of the polynomial hierarchy. variables y 1 , . . . , y m , x 1 , . . . , x k . The validity problem of such quantified formula is Ð P 2 -hard (see e.g. [33] ). For a given quantified formula, we shall construct an instance of the ON problem such that the formula is valid if and only if the ON problem with up to m link failures (where m is the number of y-variables) has a positive answer. The reduction uses the construction from Theorem 8 where we described a reduction from the validity of the formula ?x 1 , x 2 , . . . , x k . ?. The construction is further enhanced by introducing new nodes y j , y j , e j and new edges of capacity 2n (where n is the number of clauses) such that C(y j , y j ) = C(y j , e j ) = 2n, for all i, 1 ? j ? m. Now for every clause c i we add the so-called m-unbreakable edge of capacity n from c s i to y j and from e j to c e i for all 1 ? i ? n and 1 ? j ? m. Moreover, whenever the literal y j appears in the clause c i , we also add an m-unbreakable edge from y j to c e i and whenever the literal y j appears in the clause c i , we add m-unbreakable edge from c s i to y j . The construction of m-unbreakable edges (denoted by double arrows) is given in Figure 4c where the capacity of each link is set to n. Finally, for each j, 1 ? j ? m, we add the unbreakable edges from s 1 to y j and from e j to s k . The flow demands in the newly constructed network are identical to those from the proof of Theorem 8 and the weights of all newly added edges are set to 1 and we set the weight of the two links s 0 to x 1 and s 0 to x 1 to 6. The reduction can be clearly done in polynomial time. Figure 4b demonstrates an extension of the construction from Figure 4a with additional nodes and links that complete the reduction. Observe, that even in case of m link failures, the unbreakable links that consist of m + 1 edge disjoint paths are still capable of carrying all the necessary flow traffic. We shall now argue that if the formula ?y 1 , y 2 , . . . , y m . ?x 1 , x 2 , . . . , x k . ? is valid then the constructed instance of the ON problem with up to m link failures has a solution. We notice that any subset of up to m failed links either breaks exactly one of the newly added edges (y j , y j ) and (y j , e j ) for all j, 1 ? j ? m, in which case this determines a valid truth assignment for the y-variables and as in the previous proof, the flow from s 0 to s k can now be routed so that for each clause there is at least one satisfied literal. Otherwise, there is a variable y j such that both of the edges (y j , y j ) and (y j , e j ) are present and all flow demands can now be routed through these two edges (that have sufficient capacity for this) by using the m-unbreakable edges. The opposite direction where the formula is not valid means that there is a truth assignment to the y-variables so that irrelevant of the assignment for x-variables there is at least one clause that is not satisfied. We simply fail the edges that correspond to such a y-variables assigment and the same arguments as in the previous proof imply that there is not any feasible flow assignment for this failure scenario. Proof sketch. By reduction from the NP-complete shortest path most vital edges problem (SP-MVE) [3, 36] . The input to SP-MVE is a directed graph G = (V, E) with positive edge weights, two nodes s, t ? V and two positive numbers k and  construct network N F and weight assignment W F by Definition 3 5: switch ô do 6: case OS: use Theorem 1 on N F and W F (without failed links) 7: case ON: use Theorem 2 on N F and W F (without failed links) 8: case PS/PN: use Theorem 3 on N F and W F (without failed links) 9 : if the answer to the ô -problem on N F and W F is negative then return false 10: endfor 11: return true H. The question is whether there exist at most k edges in E such that their removal creates a graph with the length of the shortest path between s and t being at least H. We reduce the SP-MVE to the negation of the PN/PS in order to demonstrate co-NP-hardness. We modify the G by inserting a new edge between s and t of weight H and capacity 1, while setting the capacity 2 for all other edges in G. If the SP-MVE problem has a solution F ? E where |F | ? k, then the added edge (s, t) becomes one of the shortest paths between s and t under the failure scenario F and a flow demand of size 2 between s and t can be routed through this edge, violating the capacity constraints. If the SP-MVE problem does not have a solution, then after the removal of at most k links, the length of the shortest path between s and t remains strictly less than H and any flow assignment along the shortest paths is feasible. We hence conclude that PN/PS problems are co-NP-hard. A small modification of the construction is needed for hardness of the OS problem. In order to solve the PS, PN, ON and OS problems, we can enumerate all failure scenarios for up to k failed links (omitting the links with zero capacity), construct the pruned network for each such failure scenario and then apply our algorithms in Theorems 1, 2 and 3. This brute-force search approach is formalized in Algorithm 2 and its worst-case running time is exponential. Our complexity results indicate that the exponential behavior of any algorithm solving a co-NP-hard (or even Ð P 2 -hard) problem is unavoidable (unless P=NP). However, in practice many concrete instances can be solved fast if more refined search algorithms are used. To demonstrate this, we present a novel strategic search algorithm for verifying the feasibility of shortest path routing under failures. At the heart of our algorithm lies the idea to reduce the number of explored failure scenarios by skipping the "uninteresting" ones. Let us fix an NCD N = (V, C, D) with the weight assignment W . We define a relation ? on failure scenarios such that F ? F iff for all flow demands we preserve in F at least one of the shortest paths that are present under the failure scenario F . We first show that if F ? F and the failure scenario F has a feasible routing solution for the pessimistic problem, then F also has a solution. Thus instead of exploring all possible failure scenarios like in the brute-force algorithm, it is sufficient to explore only failure scenarios that are minimal w.r.t. ? relation. Hence for the pessimistic scenario, the idea of strategic search is to ignore failure scenarios that remove only some of the shortest paths but preserve at least one of such shortest paths. For the optimistic scenario, we on the other hand explore only the maximal failure scenarios where removing one additional link causes the removal of all shortest paths for at least one source and destination. In our algorithm, we use the notation spg s,t F for the shortest path graph as defined in Algorithm 1 for the input graph N F with weight assignment W F . The function min cuts(spg s,t F , s, t) returns the set of all minimum cuts separating the nodes s and t (sets of edges that disconnect the source node s from the target node t in the shortest-path graph spg s,t F ). This function can be computed e.g. using the Provan and Shier algorithm [34] , assuming that each edge has a unit weight and hence minimizing the number of edges in the minimum cut. There can be several incomparable minimum cuts (with the same number of edges) and by mincut size(spg s,t F , s, t) we denote the number of edges in each the minimum cuts from the set min cuts(spg s,t F , s, t). Algorithm 3 now presents our fast search strategy, called strategic search. The input to the algorithm is the same as for the brute-force search. The algorithm initializes the pending set of failure scenarios to be explored to the empty failure scenario and it remembers the set of passed failure scenarios that were already verified. In the main while loop, a failure scenario F is removed from the pending set and depending on the type ô of the problem, we either directly verify the scenario F in the case of the pessimistic problems, or we call the function MaxFailureCheck (F ) that instead verifies all maximal failure scenarios F such that F ? F . The correctness of Algorithm 3 is formally stated as follows. Theorem 11. Algorithm 3 terminates and returns true iff the answer to the ô -problem is positive.  To evaluate the practical performance of our strategic search algorithms, we conducted experiments on various wide-area and datacenter network topologies. The reproducibility package with our Python implementation can be found at [37] . We study the algorithms' performance on a range of network topologies, and consider both sparse and irregular wide-area networks (using the Internet Topology Zoo [28] data set) as well as dense and regular datacenter topologies (namely fat-tree [9] , BCube [23] , and Xpander [40] ). To model demands, for each topology, we consider certain nodes to serve as core nodes which have significant pairwise demands. Overall, we created 24,388 problem instances for our experimental benchmark, out of which we were able to solve 23,934 instances within a 2-hour timeout. In our evaluation, we filter out the trivial instances where the runtime is less than 0.1 second for both the brute-force and strategic search (as some of the instances e.g. contain a disconnected flow demand already without any failed links). The benchmark contains a mixture of both positive and negative instances for each problem for increasing number k of failed links. Table 5 shows the median times for each series of experiments for the different scenarios. All experiments for each topology and given problem instance are sorted by the speedup ratio, i.e. B.time divided by S.time; we display the result for the experiment in the middle of each table. Clearly, our strategic search algorithm always outperforms the brute-force one by a significant factor in all the scenarios. We also report on the number of iterations (B.iter and S.iter) of the two algorithms, showing the number of failure scenarios to be explored. Let us first discuss the pessimistic scenarios in more detail. Figure 6 shows a cactus plot [6] for the wide-area network setting (on the left) and for the datacenter setting (on the right). We note that y-axis in the figure is logarithmic. For example, to solve the 1500th fastest instances in the wide-area network (left), the brute-force algorithm uses more than 100 seconds, while the strategic algorithm solves the problem in less than a second; this corresponds to a speedup of more than two orders of magnitude. For more difficult instances, the difference in runtime continues to grow exponentially, and becomes several orders of magnitude. For datacenter networks (right), the difference is even larger. The latter can be explained by the fact that datacenters provide a higher path diversity and multiple shortest paths between source and target nodes and hence more opportunities for a clever skipping of "uninteresting instances". As the pessimistic problems we aim to solve are co-NP-hard, there are necessarily some hard instances also for our strategic search; this is demonstrated by the S-shaped curve showing a significantly increased runtime for the most difficult instances. We next discuss the optimistic scenarios, including the experiments both for splittable and nonsplittable cases. Figure 7 shows a cactus plot for the wide-area network setting (on the left) and for the datacenter setting (on the right). Again, our strategic algorithm significantly outperforms the baseline in both scenarios. Interestingly, in the optimistic scenario, the relative performance benefit is larger for wide-area networks as the optimistic strategic search explores all the maximum failure scenarios and there are significantly more of such scenarios in the highly connected datacenter topologies. Hence, while for datacenters (right) the strategic search maintains about one order of magnitude better performance, the performance for the wide-area networks improves exponentially. We presented a comprehensive study of the algorithmic complexity of verifying feasible routes under failures without violating capacity constraints, covering both optimistic and pessimistic, as well as splittable and nonsplittable scenarios. We further presented algorithms, based on strategic failure scenario enumerations, which we proved efficient in realistic scenarios. While our paper charts the complete landscape, there remain several interesting avenues for future research like further scalability improvements and a parallelization of the algorithm. 