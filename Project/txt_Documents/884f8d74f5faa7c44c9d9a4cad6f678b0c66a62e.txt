Journal Pre-proof Using social media data for assessing children's exposure to violence during the COVID-19 pandemic Using social media data for assessing children's exposure to violence during the COVID-19 pandemic
Pouria Babvey, Fernanda Capela, Claudia Cappa, Carlo Lipizzi, Nicole Petrowski, Jose Ramirez-Marquez
empty
The COVID-19 pandemic brought unforeseen challenges that could forever change the way societies prioritize and deal with public health issues. The approaches to contain the spread of the virus across the world have been wide-ranging. Some common approaches have entailed governments issuing recommendations on social distancing for parts or all of their countries as well as suspension of services, from education and childcare to child protection. In other cases, lockdowns were declared with restrictions for all non-essential movements. Among other concerns, the measures adopted by countries in response to the pandemic may have led to a surge in certain forms of violence against children. The suspension of schools has placed an added burden on families as they struggle to balance childcare, education and work responsibilities. The effects of economic pressure due to reduced or negative economic growth and associated insecurity and uncertainty, job loss, or disruption to livelihoods may increase family violence. Confinement measures have resulted in families spending more time together, J o u r n a l P r e -p r o o f which could lead to heightened tensions in the household. All of this, in combination with social isolation, may mean that children face an increased risk of experiencing violence at home (Bradbury-Jones & Isham, 2020; Lee & Ward, 2020;  The Alliance for Child Protection in Humanitarian Action, 2019). Other factors may also have an impact including that children spend more time online during the pandemic (World Childhood Foundation et al., 2020) . Due to stay-at-home orders, schools needed to provide online education and children have been required to use applications and digital platforms. Meanwhile, as they were unable to meet friends in-person, children have connected via text messages and social media more often. When children are using educational platforms that demand interactions through posts and comments and they are more connected with peers online, the opportunity for cyberbullying and other forms of online violence increases. Confinement and disruption of child protective services could cause children who experience violence at home and online to suffer in silence. During the crisis, it is likely more difficult to identify children at risk as many adults who would typically identify signs of abuse and maltreatment (e.g. teachers, childcare workers, coaches, extended family, community members, child and family welfare workers) are no longer in regular contact with children. Therefore, practitioners and institutions that work with children would benefit from analyses of available data that can offer insights into how children's experience of certain forms of violence has changed during the pandemic. Most of the current evidence on the impact of the pandemic on violence against children comes from service providers (Baron, Goldstein, & Wallace, 2020; Benson, Fitzpatrick, & Bondurant, J o u r n a l P r e -p r o o f 2020; Peterman, O'Donnell, & Palermo, 2020) , and as such cannot be used to assess changes in actual experience of violence. Indeed, data gathered from authorities and those in charge of providing services to children and their families only document cases that are reported to, and reached by, prevention and response mechanisms (UNICEF, 2020) . These represent only a small portion of all episodes and victims of violence (UNICEF, 2014) . Prevalence data, derived from population-based surveys, are needed to obtain representative estimates on the number and characteristics of children who experience violence and to assess trends over time. However, such surveys have been put on hold in many countries due to COVID-19 restriction measures. Additionally, due to safety concerns for victims and researchers, as well as methodological constraints, surveys that ask direct questions on the experiences of violence are not advisable during the pandemic (Bhatia, Peterman, & Guedes, 2020; UN Women & World Health Organization, 2020) . Even prior to the pandemic, large-scale prevalence studies of children's exposure to violence have been scant and statistics on this topic have remained inconsistent in scope and quality (Cappa & Petrowski, 2020) . While data on violence at home has increased significantly over the last 15 years, forms of abuse that are particularly challenging to measure, such as commercial sexual exploitation, have been largely ignored in data collection (Cappa & Petrowski, 2020) . Other topics, such as online abuse, have almost exclusively been investigated in high-income countries (UNICEF, 2014) . A survey of 44 countries in Western Europe and Canada (conducted between 2017 and 2018) found that the proportion of adolescents who had been cyberbullied varied widely among the participating countries, from 3 percent among 15-year-old boys in Spain to 29 percent among 15-year-old boys in Lithuania (Inchley, Currie, Budisavljevic, Torsheim, J?stad, Cosma, et al., 2020) . Given the constraints associated with survey data, social media can be leveraged to gather insights into children's wellbeing and their exposure to violence. Twitter is one such source of information. This microblogging and social networking service allows users to post and interact with messages known as tweets, which can have a maximum length of 280 characters. Unlike most social networks that require users to be at least 13 years of age, children of any age can sign up to Twitter. Additionally, the content posted on Twitter is available and visible to all users, without network restrictions. According to Statista, as of July 2020, there were approximately 330 million Twitter users, of whom 8 percent were below the age of 18. The United States, Japan, India, Brazil, the United Kingdom and Turkey have the greatest number of users on Twitter with respectively, 62, 49, 17, 15, 15, and 12 million users. The official website of Twitter notes that policies are in place to address abusive behaviors and regulate age screening for the purpose of filtering advertisements. Abusive behaviors are defined as any attempt to harass, intimidate, or silence someone else's voice. Abusive or harmful content can be reported and users who are found to engage in such content may have their posts censored or accounts suspended, depending on the gravity of the offense. Of particular value in the understanding of what topics are most popular on the web are moderated forums that allow discourse between users. Reddit is a social media site with a wide range of forums dedicated to various topics, called subreddits, each of which is moderated by community volunteers. According to Reddit's user agreement, children under the age of 13 are not allowed to create an account or otherwise use the services, even though there is no real way to enforce that requirement. As of 2020, there are over 430 million monthly active Reddit users and Reddit has over 1.2 million different subreddits (Djordjevic, 2020) . Among all the users, 7 percent are under age 18 (Response Agency, 2014). For subreddits dedicated to sensitive topics J o u r n a l P r e -p r o o f such as depression, domestic abuse, and suicide, the moderators tend to ensure that the anonymous submitter has access to local help hotlines if a life-threatening situation is described. They also enforce respectful behavior by deleting disrespectful or off-topic posts (Schrading et al., 2015a) . Users can also report abusive content, which is evaluated by the platform administrators. Unlike Twitter, Reddit allows lengthy submissions, which grant opportunities to cover sensitive subjects that may not typically be discussed in social media. This also makes it possible to apply natural language processing tools for the analysis of the testimonials. The use of social media platforms to report experiences of violence has grown over the years, alongside academic literature that used such sources to understand patterns of victimizations. In 2014, Twitter users unequivocally reacted to the assault scandal of Ray Rice, a former American football running back, by unleashing personal stories of domestic abuse via the hashtags #WhyIStayed or #WhyILeft. Schrading et al. (2015b) used natural language processing models to extract micro-narratives of both staying and leaving which included reference to cognitive manipulation, financial constraints, keeping family united, and experiencing shame for #WhyIStayed; and fearing physical violence, realizing self-worth, gaining support, and gaining agency for #WhyILeft. Another major case occurred in 2016, when Twitter hashtag #MaybeHeDoesntHitYou triggered an outpouring of victims' stories detailing their personal experience of abuse (Mccauley et al., 2018) . Researchers have also worked on applying tools for automatically detecting reports of violence on social media. In a study by Pettyjohn et al. (2019) , a dataset of Facebook posts about domestic violence was collected and manually classified into five categories: Awareness, Empathy, Fund Raising, Personal Story, and General. According to the results, machine learning models could efficiently label the post into one of the above-mentioned categories. Several studies have also J o u r n a l P r e -p r o o f worked on developing models for automatically tagging hate speech and other abusive content on social media. These models mainly used data from Twitter, manually classifying the tweets into abusive and non-abusive using crowdsourcing, and finally train a model for further classifications (Founta et al., 2018; Davidson et al. 2017; Waseem et al. 2016; Ousidhoum et al., 2019) . Technology-facilitated abuse has also been recognized as a new form of violence and refers to controlling, monitoring and harassing behaviors using tools such as mobile phones, email, tracking apps and social media (Douglas et al., 2019) . The frequency and nature of abusive behaviors suggest this is a key form of abuse deserving more significant attention (Douglas et al., 2019) . Reddit has been studied less in this area, with work mainly focusing on mental health. In Pavalanathan and De Choudhury (2015) , a number of subreddits focusing on mental health topics were identified and used to determine the differences in discourse between throwaway and regular accounts. This study proposes a framework to assess changes in children's exposure to violence during the COVID-19 pandemic using information from social media. It utilizes data collected from Twitter users in 16 countries, as well as information gathered from Reddit in one country. Conversations on Twitter were reviewed to detect cases of abusive or hateful content, and cyberbullying, while testimonials from Reddit forums were examined to monitor changes in references to domestic violence and child physical abuse during the pandemic. In addition, the paper discusses the implications of using such information to make inferences about the impact of the stay-at-home restrictions on violence against children. Figure 1 shows the process scheme, composed of sequential stages, that was used to assess changes in children's exposure to abusive or hateful content, and cyberbullying via conversational social media interactions on Twitter during stay-at-home restrictions. Twitter is chosen for this study as it is one of the most widely used social media platforms in the world and its microblog format permits public conversations between users. Unlike Instagram, Snapchats and Facebook, which rank higher among young users (Chen, 2020) , Twitter does not rely as much on videos and images, as engagement mostly happens through textual posts and reposts. Additionally, Twitter has an open data policy that allows for the easy collection of large samples of exchanges filtering by keywords, time stamp, and/or geographic location. The first unit of the analysis considers users across the 50 States in the United States of America (USA). The sampling frame includes all the users who (1) have a verified account and with a location publicly listed in their profiles (2) in which the location is limited to the USA boundaries (3) and posted at least one tweet (or a reply to another tweet) in the time interval between January 2019 to present, (4) and contains one or some abusive or hateful keywords. The USA was selected for the first unit because at the end of March 2020, the country became the epicenter of the COVID-19 pandemic and by July 2020, the Centers for Disease Control and Prevention was reporting that the country had surpassed the mark of four million coronavirus cases, which is over 25 percent of the total cases worldwide. The first stay-at-home restrictions that ordered the closure of stores and schools came into effect in the first week of March; J o u r n a l P r e -p r o o f however, a wide range of measures were implemented across the different States at different times, which did not always mirror the evolution of the pandemic (Lee, 2020) . <Figure 1 about here>-Approach to assessing change in cyberbullying and abusive or hateful content on Twitter The first stage of the process entailed the selection of a vast number of textual conversations containing abusive or hateful content, or related to cyberbullying, using a pretrained model on a labelled dataset to detect the tweets with abusive or hateful contents. Abusive language refers to any strongly impolite, rude or hurtful language using profanity, that can show a debasement of someone or something, or convey intense emotion (Founta et al., 2018; Park & Fung, 2017; Papegnies, 2017) . Hateful messages express hatred towards a targeted individual or group, or is intended to be derogatory, to humiliate, or to insult the members of the group, on the basis of attributes such as race, religion, ethnic origin, sexual orientation, disability, or gender (Davidson et al., 2017) . Cyberbullying can be defined as the use of force, threat, or coercion to abuse, embarrass, intimidate, or aggressively dominate others, using electronic forms of contact. It typically denotes repeated and hostile behavior exhibited by a group or an individual (Chatzakou et al., 2017) . The conversations were labeled as non-abusive/normal, abusive, hateful, or neutral/uncertain using a Machine Learning algorithm that was trained from a pre-classified dataset. Only tweets containing abusive or hateful language were retained. It is worth mentioning that the classifier found the conversations that contained abusive language among users and did not consider posts in which users discuss their concerns about cyberbullying, potential solutions, J o u r n a l P r e -p r o o f etc. Users in social media can be individuals posting about their lives, or institutions, such as newspapers, sharing the latest news and articles, etc. Posts containing the word "cyberbullying" are likely to be about cyberbullying, but not necessarily have bullying content. Thus, the classifier labels the news articles, academic and institutional studies as normal. This is an important filter as increase in tweets may be due to more conversations about a topic, rather than an increase in experiences of an issue. For instance, between March 2019 and April 2020, we collected tweets containing the keyword 'cyberbullying' from New York City. The weekly citations of 'cyberbullying' increased from an average of 20 to 170 citations around March 2020, when the United States started to implement stay-at-home restrictions (results not shown). This substantial spike indicates that cyberbullying became a trending topic once the stay-at-home restrictions started. However, this does not mean that there were more cases of cyberbullying in New York City, as these citations can include news articles, experts' predictions, institutional analysis, academic papers, parents' concerns, etc. Indeed, the filtering model found that on average, only 30 percent of the tweets contained hateful or abusive language. During this process, the metadata containing the sources and dates of the posts were maintained. Once the desired posts were filtered, they were reorganized by date (before and after the stay-athome restrictions) and by geographic location. The metric used to assess the increase or decrease in abusive tweets was the number of posts per week normalized by the size of the population in the relevant location. Then, these weekly counts were averaged for dates before and after the stay-at-home restrictions started. To extend the geographic scope of the analysis, 15 more countries around the world were selected as case studies for the second unit of analysis. The sampling frame includes all the users who (1) have a verified account and with a location publicly listed in the profiles (2) A scraping tool was used to gather the tweets, which were later merged into a dataset. A multilingual deep learning model XLM-R, developed in 2019 by Facebook (Lample, 2019; Wu, 2019) , was used to aggregate the textual knowledge in different languages. To train the model for abusive message detection, 100,000 tweets published in a study from Founta et al. (2018) were used. Each tweet in that study was classified by a group of five individuals into one the following categories: normal, abusive, spam, and hateful. A majority vote was then used as the final label for each tweet. Among all the tweets, 55 percent were labeled as normal, 26 percent as abusive, 14 percent as spam, and 5 percent as hateful. After training and tuning, the model was applied to our dataset, and tweets were classified into one of the four categories listed above. The model was able to predict the labels of tweets with a 77 percent accuracy and with Cohen's kappa equal to 0.64 (results not shown). Only posts classified as hateful or abusive were considered. To evaluate the performance of the model on languages other than English, a set of 1,000 tweets in Spanish, French, Indonesian, and Arabic (250 tweets from each language) were selected randomly and then manually classified into one of the four mentioned categories. The model was able to label the tweets correctly with 76 percent accuracy compared to 25 percent random assignment (results not shown). Although the model showed a reliable performance in detecting the abusive messages, it may have some biases between different languages. However, in this study, the ratio of abusive content between different languages is not used and the analysis relies on comparing the abusive content ratio for each country at different periods of time. The last stage entailed the compilation of other data to evaluate which features might be crucial to influencing the changes in abusive content. A correlation analysis was performed for the 15 countries between changes in abusive content and human development, as measured by the HDI. For Reddit, a testimonial-based approach was used to measure changes in violence-related conversations during the pandemic. While Reddit does not rank among the most commonly used social media platforms by children, it was selected in light of the lengthy texts that users can submit, which allows for more refined content analyses. The sampling frame of the analysis on Reddit includes all the users who submitted at least one post to one of the subreddits listed in Figure 7 during the data collection time interval of the 18 months between January 2019 and July 2020. As the majority of the Reddit users, specifically in the violence-related subreddits, are from the United States, the results may not be generalized to the international level. As a first step, subreddits that focused on family violence were selected. Family violence is defined here as any form of abuse committed by one family member against another, including cases of child maltreatment as well as children's exposure to intimate partner violence. Three abuse-related subreddits were selected, i.e. abuse, survivors of abuse, and domestic violence. Table 1 shows the number of users that were engaged in the three subreddits as of June 2020, as well as the total number of abuse-related posts that were found in 2019 and 2020. Table 2 ). Among all the posts, 42 percent were about intimate partner abuse, 22 percent about physical abuse, 18 percent about sexual abuse, 11.5 percent about child abuse, and 6.5 percent about practitioners' support. One main distinction between physical abuse and intimate partner abuse here is that the model assigned physical abuse to the posts that were reporting physical acts while it assigned intimate partner abuse to the cases that mainly discussed cognitive manipulation, financial strain, etc. <Table 2 about here>-Main topics in abuse-related subreddits and most frequently used keywords Additionally, subreddits dedicated to sensitive topics such as depression, suicide, relationship disorders, etc. were added as control groups. Comparing violence reports with other types of reports allows for a more accurate estimation of changes, as more people may have used social media as a medium to share their personal experience during the stay-at-home restrictions when other forms of interactions were limited. Python Reddit Application Programming Interface (API) Wrapper (PRAW) was used to extract the data. In the pre-processing step, links, usernames, numbers, and stop words (i.e., most common, short function words, such as the, is, at, out) were removed. Also, all the posts were normalized by lowercasing and lemmatizing (Balakrishnan & Lloyd-Yemoh, 2014) . Topic modeling was used to extract the posts, categorize the posts into different types of abuse, and measure the share of each topic before and after the stay-at-home restrictions. Topic modeling algorithms categorize a set of posts into a number of different groupings. In this study, the Latent J o u r n a l P r e -p r o o f Dirichlet Allocation (LDA) algorithm was used for topic modeling. LDA (Blei et al., 2003) was developed based on generative statistical models, and most of the existing topic modeling methods are an extension or a variation of LDA (Wang et al., 2012; Chen et al., 2015) . LDA draws a distribution over words per topic and a distribution over topics per document. Then, the most frequent words in each topic are selected as keywords. Finally, based on the set of the generated keywords for different categories, one can assign a proper topic to each category. To calculate the growth of the number of abuse-related reports on Reddit, the daily average number of posts in the selected subreddits before and after the stay-at-home restrictions were compared. March 17th, 2020 was used as the beginning of the stay-at-home in the United States (based on the University of Oxford's Coronavirus Government Response Tracker). The analysis of Twitter data shows a significant increase in abusive content generated during the stay-at-home restrictions. A spike in such tweets can be observed after March 2020, across different States. As shown in Table 3 , the District of Columbia shows the highest increase in abusive tweets, followed by New With the increase of social media usage during the stay-at-home restrictions, it was expected that the numbers of tweets would increase. However, the overall increase in Twitter usage after the stay-at-home restrictions started has been 24 percent (The Washington Post, 2020), which is much smaller than the average weekly increase in abusive tweets. Table 4 shows commonly used ngram (i.e. a sequence of n items from a given text) that were extracted from the abusive or hateful tweets posted in the reference period. It is worth noting that some of the expressions that appeared after the stay-at-home restrictions started, such as those shown in bold in the table, seem to defend cyberbullying or even show pride in the action. <Table 4 about here>-Ngrams extracted from abusive tweets before and after the stay-at-home restrictions started Figure 3 presents the change in abusive and non-abusive tweets between November-December 2019 and March-April 2020 for the additional 15 countries. The number of abusive messages increased in all the countries, but Sweden. The growth was particularly significant in Indonesia, the Philippines, Portugal, and Brazil with a more than 30 percent increase compared to 2019. One possible explanation could be that due to the stay-at-home measures more people, especially adolescents, were actively using Twitter. However, Figure 3 also shows that the growth of abusive content has been more significant than the increase in non-abusive content. and March-April 2020, by whether the tweets were abusive or non-abusive Finally, Figure 4 and Figure 5 show the growth rate of abusive tweets and the Stringency Index (SI), and the growth rate of abusive tweets and Human Development Index (HDI) respectively, for the 15 countries. On the one hand, the growth of abusive content was not clearly nor strongly correlated with the SI. On the other hand, a negative correlation was found between the growth in abusive content and the HDI scores. Based on the statistical analysis results, the correlation coefficient between the HDI and abusive content growth rate is 0.7 while the correlation between the SI and abusive content growth is 0.33. <Figure 4 about here> -Ratio between the number of tweets from November-December 2019 and March-April 2020, and SI <Figure 5 >-Ratio between the number of tweets from November-December 2019 and March-April 2020, and HDI The analysis of Reddit shows that violence-related subreddits were among the topics with the highest growth after the COVID-19 outbreak. Figure 6 shows the average weekly posts in subreddits on sensitive topics, expressed as a ratio. The three abuse-related subreddits were among those with the largest increase in level of activities after the stay-at-home restrictions started. Topics like r/selfhelp, r/selfharm, r/insomnia, J o u r n a l P r e -p r o o f and r/anger also show significant growth, while others like r/socialanxiety, r/stopdrinking, and r/bipolar do not show a significant change. <Figure 6 about here>-Ratio of the number of weekly posts to the average in the 18 months between January 2019 and July 2020, for selected subreddits Figure 7 shows the ratio in the average daily number of posts before and after the stay-at-home restrictions. After the stay-at-home restrictions started, this figure is almost 35 percent higher than the daily average before the restrictions went into effect. However, for the r/abuse, r/selfhelp and r/survivorsofabuse the growth is more significant, while for others like r/socialanxiety and r/stopdrinking the results actually show a decrease. <Figure 7 about here>-Ratio of the number of daily posts before and after the stay-at-home restrictions started for selected subreddits To see how much of the increased content in abuse-related subreddits was produced by newly active users, the date of the first message of each user was recorded from the beginning of 2019 until the end of June 2020. Figure  The analysis of Twitter and Reddit data shows an increase in abusive or hateful conversations and violence-related testimonials on these social media platforms after confinement measures were enacted. More specifically, abuse-related subreddits were among those with the highest activity growth after March 17 th , 2020. This was the date that stay-at-home restrictions began in many States within the USA. The growth in testimonials related to abuse was higher than the growth in posts about other sensitive topics, including mental health. These findings should be considered in light of other research and studies which have found that COVID-19 restriction measures have inhibited the reporting of child maltreatment to authorities and professionals, such as teachers, who are typically in regular contact with children (see for example: Baron, Goldstein, & Wallace, 2020) . This might suggest that, given the increased online presence of both children and adults, service providers should explore innovative ways through which social media and virtual platforms might be used to identify potential victims of violence. Furthermore, J o u r n a l P r e -p r o o f to also consider how these platforms could act as entry points for setting up reporting and referral mechanisms as well as the provision of support services. This, of course, needs to be done in ways that guarantee confidentiality and privacy of the victims and does not expose them to further harm. Similarly, there was a notable increase in the use of abusive or hateful language on Twitter in the USA after March 1 st , 2020 as compared to before this period. The observed rise in abusive online content was not restricted just to the USA. The fact that the growth of abusive content during the pandemic was not strongly associated with the Stringency Index implies that increased exposure to harmful content online is occurring across the world regardless of how strict a government's response to COVID-19 has been. This might point to reasons other than the severity of the measures being behind the increase in abusive content, including increased concerns and stress deriving from the pandemic and related containment measures and socioeconomic impacts. Regardless of whether or not children themselves are being targeted or victimized, the public nature of the content means that children are at risk of being exposed to such abusive language and negative interactions between online users and this poses a risk to their well-being. This means that response and increased safety mechanisms need to be developed and put into place to prevent children's further exposure to abusive content as the global culture shifts towards an increasingly digital world. ICT companies and social media platforms have an important role to play in keeping children safe online by establishing or strengthening policies and mechanisms for privacy and protection of users from abusive content. A limitation of the study is that it was not possible to restrict the analyses to only those involving children for two main reasons. The first has to do with privacy and the second is due to J o u r n a l P r e -p r o o f limitations with users disclosing their age (or being truthful about their age) as part of their online profile. For this reason, the findings cannot be taken as an indication of children directly experiencing increased cyberbullying but should rather be interpreted as evidence of the potential for children to be exposed to increasingly abusive content while online. Similarly, the growth in violence-related testimonials on Reddit cannot be interpreted as conclusive of increases in family violence, as this may be due to extended online presence and lack of other venues through which users can talk about their experiences. Caution is warranted when interpreting the findings from both sets of analyses and the results should not be generalized to other country settings since the majority of Reddit users, and in particular those accessing subreddits about violence, are known to be based in the USA. At the same time, the Twitter analysis was carried out on only 15 countries (in addition to the USA). The current study demonstrates the potential for using social media data to shed light on children's exposure to violent content online. Future research and additional analysis are needed to zoom in on the specific experiences of children online during the COVID-19 pandemic. Finally, the approach used in this paper to analyze abuse-related content on social media proved effective in identifying patterns and assessing trends. The application of such an approach to other subjects should be explored. The COVID-19 pandemic and related containment measures offer insights into the wide-ranging risks that children are exposed to in times of crisis. In documenting an increase in abusive posts on social media during the stay-at-home restrictions, this paper identifies the need for safe and J o u r n a l P r e -p r o o f effective remote-access support mechanisms. The growth in violence-related testimonials online sheds light on the role of social media platforms as venues for disclosing experiences of abuse and, possibly, counseling in times when in-person interactions are limited. As societies shift towards a new normal, with technology, remote working and learning at its center (and anticipating similar future threats) governments and other stakeholders need to adopt measures to support families, regulate online platforms and strengthen services as they work to protect children from all forms of violence. Notes: The size of the circles is proportional to the average daily number of posts for each subreddit. Small-size and mid-size subreddits are displayed in the left side of the figure and large subreddits are located on the right side. OCD stands for obsessive-compulsive disorder; BPD stands for borderline personality disorder; EOOD stands for exercise out of depression; SLP stands for speech-language therapy; and MMFB stands for make me feel better.  