Privacy-preserving Travel Time Prediction with Uncertainty Using GPS Trace Data
Fang Liu, Dong Wang, Zhengquan Xu
The rapid growth of GPS technology and mobile devices has led to a massive accumulation of location data, bringing considerable benefits to individuals and society. One of the major usages of such data is travel time prediction, a typical service provided by GPS navigation devices and apps. Meanwhile, the constant collection and analysis of the individual location data also pose unprecedented privacy threats. We leverage the notion of geo-indistinguishability (GI), an extension of differential privacy to the location privacy setting, and propose a procedure for privacy-preserving travel time prediction without collecting actual individual GPS trace data. We propose new concepts to examine the impact of the GI sanitization on the usefulness of GPS traces, and provide analytical and experimental utility analysis of the privacy-preserving travel time reliability analysis. We also propose new metrics to measure the adversary error in learning individual GPS traces from the collected sanitized data. Our experiment results suggest that the proposed procedure provides travel time analysis with satisfactory accuracy at reasonably small privacy costs.
The rapid growth of GPS technology and mobile devices has led to a quick accumulation of massive location data. While collection and applications of location data provide enormous benefits and convenience to individuals and society, processing of location information can easily expose personal behaviors, interests, social relations, or other private information, especially if combined with other data sources. [1] studies human location movement data of 1.5 million people for 15 months and concludes that as little as four space-time points can uniquely identify 95% individuals. In the COVID-19 pandemic, tracing apps have been used in some countries to collect individual spatiotemporal data to identify and isolate those who came into contact with COVID-19 patients, raising privacy concerns [2] [3] [4] . On the * Co-first authors. top of that, users are often not fully aware of the privacy risks from sharing their personal location information with servers and how their data are used [5, 6] . To mitigate the privacy risk associated with collection and analysis of location data, several location privacy protection frameworks have been proposed, including encryption, anonymization and obfuscation. Location encryption methods [7] [8] [9] [10] [11] [12] [13] often come with high computational and resource costs [14] . Once decrypted, the data are no longer private, though still safe, to those who have the authority to access and view the data. In other words, the privacy:utility ratio from the data user perspective is either 100:0% or 0:100%, corresponding to the two states of encryption and decryption, respectively. These two extreme ways of providing data access often do not meet the practical needs of data sharing. As a matter of fact, a non-zero small privacy cost is often acceptable so to create more options between the two extremes to release data and share information with more data users. Location anonymization/pseudonymization and obfuscation [15] [16] [17] [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] provide one such option. These methods focus on privacy-preserving data processing and analysis via methods such as data suppression, removal of identifiers, development of perturbation mechanisms to report dummy locations, among others. If properly implemented at the data collection stage, the true responses of an individual can be made known only to the individual with 100% confidence but no one else. The key in implementing anonymization and obfuscation is to strike a good balance between privacy loss and data utility (the higher the privacy cost, the more data utility there is). The state-of-art concept for privacy protection through data obfuscation in general is differential privacy (DP) [28] . DP is a ground-breaking and mathematically robust concept for data privacy protection and has quickly become the mainstream in privacy research and applications, including adoption by big tech companies (e.g., Apple, Google, IBM) and government agencies (Census2020) of the classical DP concept or its variants. For location privacy, [20] extends DP to formulate the notion of geo-indistinguishability (GI). GI follows similar mathematical reasoning as DP, and many properties of DP are thus directly applicable to GI such as privacy loss composability [29] , immunity to post processing [30] , being future-proof [30] , and robustness to a wide range of adversary attacks [31, 32] . GI has been ex- Fig. 1 : Privacy Protection Strategies for Analysis using GPS Data plored in a wide range of applications in location privacy protection. For example, [21] extends GI by developing an elastic indistinguishability metric that adapts injected noises according to the area density. [23] proposes a clustering privacy-preserving mechanism for continuous location traces clustering application. [25] applies GI to preserve location information uploaded by passengers in vacant transportation network company vehicles. [26] proposes a GI task allocation mechanism to preserve location privacy in mobile crowd-sensing applications. We aim to develop a procedure to provide Privacy-Preserving Travel time Prediction with Uncertainty (PP-TPU) using GPS data; a topic hasn't been explored in either research or applications, to the best of our knowledge. Travel time Prediction with Uncertainty (TPU) examines whether and how quickly a person arrives at a destination through a certain means of transportation with a certain level of confidence, and is an important topic for transportation geography, urban planning, among others [33] . It is also a typical route planning service provided by navigation systems or mapping services and apps. TPU depends on collection of users' travel trajectory data by a service provider. Without sufficient privacy protection, such data can pose non-ignorable privacy risks ( Fig. 1(a) ) and it is easy for adversaries, both honest-but-curious (e.g., the service provider itself) and malicious, to infer and disclose users' private behavioral patterns and habits using the collected and released location information [34] . Fig. 1 also displays two strategies that can be used for PP-TPU. The sanitization strategy in Fig. 1(b) focuses on sanitizing aggregated statistics calculated from the actual user data, say via the randomization mechanisms (e.g, Laplace mechanism) by achieving classical DP. This strategy will mitigate the privacy risk due to adversaries learning new information about their targets from the released aggregate information, but it cannot decrease the privacy risk brought by other adversaries who can access the original collected data, such as the service provider itself. Fig. 1(c) illustrates a strategy where the sanitization occurs during data collection. In other words, the true responses are only to known the users themselves, not anyone else. To achieve this, the true individual responses will go through a sanitization mechanism prior to them being shared with the data collector or service provider. Therefore, the strategy in Fig. 1(c) is more robust than that in Fig. 1 (b) from a privacy protection perspective, and it is the strategy behind our proposed procedure for PP-TPU. The conceptual and methodological contributions of the proposed PP-TPU procedure and its potential practical impacts are summarized as follows. • We apply GI to collect GPS records from individual travel trajectories, taking into account the privacy loss composability. To improve the utility of sanitized location trajectories, we curb the number of GPS records collected per trajectory and leverage road network maps in a PP-TPU analysis to filter out the non-usable sanitized trajectories. • We propose new concepts including usable set of travel trajectories and effective number of full trajectories for a given target route, to quantify the impact of GI sanitization on the utility of sanitized trajectories for PP-TPU analysis. • We define the usefulnessconcept and different types of deviations in distance measures to examine the utility of sanitized GPS data. • We propose two new metrics continuous positioning degree and total distance to quantify the adversary error in learning individual trajectories given sanitized GPS records. • We examine the feasibility of the proposed PP-TPU procedure by quantifying the trade-off between privacy loss and the utility of sanitized GPS records and traces analytically and empirically and provide insights on choosing privacy loss parameters in different application scenarios. • Our PP-TPU procedure is easy to implement and can be easily adopted by service providers and GPS navigation systems and apps to collect user location data and provide TPU service with guaranteed privacy protection. To the best of our knowledge, there is no work focusing on PP-TPU analysis. The first step in our proposed PP-TPU procedure is to collect individual travel trajectories with privacy guarantees, on which there exists some work. First, the planar Laplace mechanism [20] can be used to perturb multiple locations from the same individual or trajectory. Due to the sequential composition of privacy costs for GI [20] and DP in general [29] , either the overall privacy cost for releasing an informative yet sanitized trajectory can be unrealistically high if the mechanism is na?vely applied to each GPS record, or the sanitized trajectory is useless if the overall cost is kept reasonable. Our PP-TPU procedure improves the practical feasibility of this approach by imposing a ceiling on the number of collected locations per individual and excluding non-usable sanitized trajectories from a TPU perspective given a target route. [22] proposes concepts "ä-location set" and "sensitivity hull" to account for temporal correlations in travel trajectories and bound the sanitization error. However, despite aiming at releasing multiple locations per trajectory, the work does not consider the composition in privacy loss in the same individual. [23] designs the clustering GI to aggregate nearby locations into a single perturbed location, which would lead to too much information loss if adopted for TPU. [21] proposes the concepts of privacy mass and elastic distinguishability to adjust the level of noises according to different area densities, offering some interesting ideas to improve the utility of PP-TPU that we plan to investigate in the future. TPU starts with collection of GPS records that contain the spatial-temporal information of a traveller, and then matches the GPS locations with physical road network maps. Each GPS record contains the location P i (latitude and longitude coordinates) and timestamp t i information. Due to satellite signal blockage, multi-path effects, and other factor that may affect GPS signals, collected GPS location information is not always accurate. It is common that direct projections of GPS coordinates may not correspond to any meaningful real map coordinate, and road mapping algorithms often involve some level of approximation. Fig.  2 shows an example of the shortest path map-matching algorithm [35] that project 3 GPS registration points onto the physical road network.  Various approaches on travel time prediction have been developed. The na?ve travel time prediction outputs a single projected travel time value, but the reachable time-space range of a traveller is rather stochastic, due to the dynamic nature of human behaviors, traffics, etc [36] . Studies [37] have shown that individuals, when facing uncertainty in travel time, tend to avoid the risk of lateness and often reserve some time to ensure that they can arrive on time with a high level of confidence [1] . It is also important for transportation and urban planning to understand the uncertainty around travel time for infrastructure development and designs, among others. The analysis of Travel time Prediction with Uncertainty (TPU) aims to obtain f (t), the probability density function (pdf) of travel time t spent over a trip with starting point A and destination B. The probability that the destination B can be reached within time b can be easily obtained from the cumulative density function (CDF) of t, that is, For example, suppose b = 10 minutes and p = 0.9, then there is a 90% chance of arriving at the destination within 10 minutes. In reality, f (t) is unknown and is often estimated by an empiricalf (t) based on collected individual travel data, such as via the GPS. Differential privacy (DP) is a state-of-art privacy protection model that guarantees privacy for released information in mathematically rigorous terms. Definition 1 ( -differential privacy [28] ). A randomization mechanism M is -differentially private, if for any pair data sets X and X that differ by one record and every possible outcome set ? to a query, where > 0 is the privacy budget or loss parameter. The smaller is, the more privacy protection there is on the individuals in the data set. X and X differ by one record may refer to the case that X and X are of the same size but differ in the attribute values in exactly one record, or the case that X is one record more than X or vice versa. The classical DP in Definition 1 is a mathematical model for privacy guarantees when releasing aggregate query results and statistics from a group of individuals. The local DP [38, 39] is an extension of the classical DP to a single user's data and can be used to develop mechanism for releasing individual responses rather than aggregate results, with privacy. for all pairs of an individual's possible personal data x and x and all possible output subset ? from M. The local DP implies that even if an adversary has access to the sanitized personal responses from a randomization mechanism that satisfies local DP, the adversary is still unable to learn much new about the user's actual responses. GI is an extension of the DP notion in the setting of location privacy and aims at releasing individual location records. In that sense, GI is more similar to the local DP concept than the classical DP; but all three concepts are based similar mathematical formulations. The formal definition of GI is given below. ). Let d(P, P ) denote the Euclidean distance between any two distinct locations P and P , and be the unit-distance privacy loss. A randomization mechanism M satisfies GI iff for all possible released location P * , any ã > 0 and any possible pair of P and P within the radius of ã, In other words, M in Eq (3) enjoys ( ã)-privacy for any specified ã, and the probability of distinguishing any two locations with a radius of ã, given the released location P * , is e ã times the probability when not having P * . For a fixed , the larger ã is, the larger the privacy loss ( ã) will be. For example, Tom is standing in Times Square in NYC and looking for a restaurant for lunch. He sends a request to a service provider for a list of restaurants nearby. However, he does not want to disclosure his exact location and chooses to release a perturbed location P * via GI with = 0.1 per mile. The probability the service provider will identify his true location within a radius of ã = 1 mile given the perturbed location information is at most 1.1 folds of the probability when not having the information, and at most 148 folds within a radius of ã = 50 miles. In the latter case, though the probability of distinguishing locations given P * dramatically increases compared to not having P * , it is not practically alarming from a privacy perspective as the increase is caused by the large ã rather than a large . In other words, the service provider will have great confident that Tom is in NYC given the released P * , but little confidence in pinpointing exactly where in NYC. If it were the combination of = 50 and ã = 1, then the probability the service provider identifying Tom's true location within a radius of 1 mile would increase by 248 folds given the perturbed location information, constituting a disastrous situation in privacy. To employ GI in location data protection, the planar Laplace mechanism can be used to perturb the coordinates of a location by injecting noises drawn from the polar coordinates. [20] ). The sanitized location P * , given the actual location P with coordinates (x, y) in the Euclidean space, satisfies GI with coordinates (x * , y * ) = (x + r cos(è), y + r sin(è)), where the joint distribution of R and è is Eq (5) implies R and è are independently distributed and In summary, to generate a sanitized location P * , one may draw R from the gamma distribution with shape 2 and scale ?1 and è from Unif(0, 2ð), and then calculate the coordinates of P * in the Euclidean space per Eq (4). Applied to the collections of GPS records, the GI notion can help to protect individual privacy on several types of information, including an individual's location at a given time point, the travel trajectory of an individual over a time period, and any derived information from the collected sanitized trajectories, including the TPU analysis. In what follows, we present a procedure to achieve PP-TPU in the framework of GI, taking into the composability of privacy costs from disclosing multiple location points from a trajectory and leveraging public knowledge of maps and road networks to improve the utility of PP-TPU on a given target road. We also examine the accuracy of sanitized information relative to the original information; analyze the privacy guarantees and indistinguishability of the proposed procedure, along with newly proposed metrics for quantifying adversary errors. Algorithm 1 lists the steps for the PP-TPU procedure. As demonstrated in Fig 1(c) , we start PP-TPU with sanitizing GPS records via GI before they are sent to and shared with the service provider. This approach mitigates privacy risks of learning new private information about an individual from the collected GPS records for various types of adversaries, as the true responses are only know to the users themselves. In addition, we take several measures to improve the accuracy of the proposed PP-TPU procedure and to quantify the utility of sanitized trajectories. First, given a fixed total per-trajectory privacy cost, we limit the number of records to be collected per traveller so that the sanitization of each location record does not inject too much noise to make the sanitized record (near) useless. Steps of the PP-TPU Procedure input : GPS location coordinates (x ij , y ij ) with timestamp ô ij for i = 1, . . . , K trajectories and j = 1, . . . , n i (? n the maximum records per trajectory); per-trajectory privacy budget i ; target route with total distance d. Perturb P j = (x ij , y ij ) via the planar Laplace mechanism in Eq (4) with privacy budget Map P * j onto the area map to obtain the map coordinates Q * j ; Second, we filter out non-usable trajectories for the PP-TPU analysis given a target route. Due to the sanitization noise injected to satisfy GI at each location, it is possible that the travel direction between two consecutive time points is opposite the target route R, which has a pre-specified direction. To not bias the total travel distance, we keep the sanitized locations as is, as long as they can be mapped onto route R, but attach a sign to indicate the travel direction consistency with R, namely, positive distance if the travelling direction is consistent with the direction of route R, negative if opposite, and 0 if the two mapped locations completely overlap. After the complete set of the GPS records from the traveller are mapped, we sum the signed distances on R for the traveller. If the summed distance is negative, then the trajectory is not usable, as defined in Definition 5. A usable trajectory given a target route is a trajectory that satisfies the following two conditions: 1) at two least consecutive locations are mapped onto the target route R; 2) the total travel distance summed over distance segments calculated from the mapped coordinates on R is non-negative. The set of usable trajectories is the usable set U. Third, we provide an option in Algorithm 1 to weigh different trajectories for their various levels of contribution towards the TPU analysis on a given target route R. The motivation behind this is given as follows. It is very possible that not all the GPS records will be mapped to the target route, even if the traveller in fact stays on R all the time at least for the time period of interest, due to a few reasons. First, GPS information is not always accurate due to satellite signal blockage and multi-path effects, causing difficulty in road matching. Second, road mapping procedures themselves often involve approximation and errors. Third, with the additional randomness introduced by the GI sanitization, the location accuracy will further decrease. Therefore, each trajectory may different number of GPS records mapped onto R, some of which are consecutive in times and others are not. When calculating the travel distance on R for a traveller, it makes sense to only count the distances between the locations at two consecutive time points if both are mapped onto R. One way to formulate the weight is to let it be proportional to how much a sanitized mapped trajectory overlaps with the target route. Definition 6 (trajectory weight). Denote by d * i the travel distance of traveller i on the target route R of length d from the usable set U. The weight that traveller i carries in the TPU analysis is With the weight being define, we can calculate the effective number of full trajectories to provide an overall metric on the impact of mapping and sanitation of GPS records on the TPU analysis on a target road. Definition 7 (effective number of full trajectory). The effective full trajectory number is K eff = i?U w i . Since w i ? [0, 1], K eff ? |U|, where |U| is the number of trajectories in U. |U| in turn is ? K, where K is the number of raw GPS trajectories before mapping, sanitation, and filtering out. K eff in a PP-TPU analysis depends on , the number of GPS trajectories K before mapping, and the pattern and complexity of the road networks onto which the GPS records are projected. Besides using weights to calculate K eff , we can also incorporate the weights in the TPU analysis by define a weighted version of f * w (t). For example, we may sample K eff travel times from set (t * 1 , . . . , t * |U | ) with the sampling probabilities proportional to w = {w 1 , . . . , w |U | } and obtain an empiricalf * w (t) based on the samples. As mentioned above, road mapping procedures involve approximation and errors, the quantification of which is challenging and case-dependent. As such, we focus on the accuracy of the perturbed GPS records relative to their original, instead of on the mapped coordinates. It is reasonable to assume that if sanitized and original GPS records are close, so are their mapped locations. First, we can quantify the closeness between a sanitized GPS location vs its original using the "usefulness" definition [20] . A location perturbation mechanism is (á, ä)-usefulness if the distance between the sanitized and original locations is ? á with a probability of 1 ? ä, for every original location. For example, for a unit-distance privacy budget = 2, the probability that a sanitized location via the planar Laplace mechanism is within á = 1.5 units of the original location is 1 ? ä = 0.8, calculated directly from the CDF of gamma(2, 1.5). If other words, the planar Laplace mechanism of = 2 GI is (1.5, 0.2)-useful for sanitizing locations. We plot the relationships between á and 1 ? ä for a range of values for the planar Laplace mechanism in Fig. 3(a) . Next, we assess the accuracy of the distance between two sanitized locations. Denote by (x j , y j ) and (x j , y j ) the coordinates of two recorded GPS locations at times ô j and ô j , respectively. The sanitized coordinates for the two locations via the planar Laplace mechanism in Eq (5) are respectively, x * j = x j + r cos(è), y * j = y j + r sin(è) x * j = x j + r cos(è ), y * j = y j + r sin(è ) , the distance between which can be calculated by the Euclidean distance where (9) ? jj = r 2 +r 2 ?2rr (cos(è j ) cos(è j ) + sin(è) sin(è ))+ 2(x j ? x j )(r cos(è ) ? r cos(è))+ 2(y j ? y j )(r sin(è ) ? r sin(è)), and d jj is the Euclidean distance between the original GPS records at times ô j and ô j . ? jj can be regarded as the bias of the squared sanitized distance from the original distance, d * jj conditional on d jj is a random variable as r, r , è, è are all random variables. We propose two metrics to examine the accuracy of d * jj relative to d jj . For the first metric, we define (d, á, ä)-usefulness for sanitized distances, in a similar manner to the (á, ä)-usefulness in general [41] and for sanitized locations [20] . A randomization mechanism is (d, á, ä)-useful, if there is a probability of 1 ? ä that the sanitized distance d * satisfies |d * /d ? 1| < á for every pair of locations with a distance of at least d. á is the relative error of the sanitized d * to the original d. The smaller á and the larger ä are for a given d, the more useful the mechanism is in terms of distance preservation. Figs. 3(b) to 3(d) depict the relationship between á and ä when the original distance d is 5, 10, and 20 at different levels of unit-distance privacy cost . As d increases, ä decreases for the same á. From the plots, we can claim that there is a 80% probability that the distance d * between the perturbed locations via the planar Laplace mechanism of = 1 GI is ±25% of d ? 10; in other words, the mechanism is (10, 0.25, 0.2)-useful at = 1. Similarly, we may also claim the mechanism is (5, 0.5, 0.2)-useful for = 1, and (5, 1.0, 0.3)-useful for = 0.5, etc. For the second metric to measure the utility of a sanitized distance, we calculate the expected and root mean squared (RMS) percentage deviations of the sanitized distance from the original distance E(d * ij /d ij ? 1) and E(d * ij /d ij ?1) 2 , respectively. Eqs (9) and (10) suggest there is no closeform expression for either of them; but we can always examine the numerical deviations for a given scenario. Table  1 lists the expected %deviation and RMS %deviation in distance for different scenarios of and d. As expected, the larger or the larger d is, the smaller the %deviation is. Also listed in Table 1 is the expected %deviation in squared distance from the original squared distance, which has a closed-form solution from Eqs (9) and (10) . Specifically, E(r 2 ) = E 2 (r) + V(r) = 6 ?2 , so is E(r 2 ), and since 2(x j ? x j )(E(r )E(cos(è )) ? E(r)E(cos(è)) + 2(y j ? y j )(E(r )E(sin(è ))?E(r)E(sin(è)) = 0, then and Eq (11) indicates that, in expectation, the squared distance between two sanitized GPS locations always deviates from the squared original distance by the same amount 12 ?2 , regardless of d ij ; however, Eq (12) implies that the deviation is not meaningful for large d ij .  As illustrated in Fig 1(c) , the proposed PP-TPU procedure is based on sanitized GPS trajectory data, mitigating the privacy risk from both the honest-and-curious and malicious adversaries. The employed privacy model, GI, is an extension of the notion of DP to location settings with a similar mathematical concept for controlling privacy loss when sharing information. DP is known to provide "provable privacy protection against a wide range of potential attacks, including those currently unforeseen" [31, 32] . The proposed PP-TPU procedure in Sec 3.1 protects several types of spatial-temporal information: the location of a traveller at a given time point, a travel trajectory of the traveller for a given time period, any calculated statistics from the trajectory (e.g, travel distance, travel speed) per the the immunity property of DP and GI against post-processing. We examine each type of the yielded privacy protection below in more detail below, especially the protection of a travel trajectory. First, per the definition of GI in Definition 3, the probability of distinguishing the true location P from any other locations with a radius of ã, given the released perturbed location P * increases by e ã ? 1 folds compared to the probability when not having P * . In other words, the same privacy guarantees and indistinguishability as illustrated in Definition 3 apply to the GPS records collected at each timestamp for the PP-TPU analysis. Second, the proposed PP-TPU procedure protects the privacy of a collected travel trajectory over a time period. Though each of the location records on the trajectory is perturbed via the planar Laplace mechanism has a straightforward interpretation on indistinguishability as presented above, how to quantify the adversary error in learning about the original trajectory based on the released sanitized trajectory is less studied. Below we propose two metrics -the total distance (TD) and the consecutive positioning rate (CPD)to quantify the adversary error and assess the effectiveness of a randomization procedure in protecting travel trajectory privacy. We apply both metrics to examine the adversary error in the experiments in Sec. 4. Definition 9 (total distance). The total distance (TD) between the sanitized and original travel trajectories is the summed distance between the two sets of GPS locations and on the sanitized and original trajectories at the same set of timestamps. Say there K trajectories. The original and sanitized coordinates on trajectory i are {(x ij , y ij )} and {(x * ij , y * ij )} recorded at time {ô ij }. The TD is calculated as For a fixed set {n i } for i = 1, . . . , K, the larger TD is, the larger the adversary error and the more difficult it is to recover the original trajectory. Definition 10 (consecutive positioning degree). The consecutive positioning degree (CPD) is a probability of distribution p(l) of correctly identified l consecutive locations on a trajectory based on the released sanitized trajectory with n GPS records, for l = 0, . . . , n. The expected value of correctly identified positions out of n is n c = n l=0 l ? p(l). We choose to examine the distribution of correctly identified consecutive positions p(l) instead of that of correctly identified positions p(m) for m = 0, . . . , n (regardless of whether they are consecutive or not) is because the former would be regarded by many as more revealing of travel trajectory and thus carrying more privacy concern than latter protection. How to define "correctly identified positions" is up to the user. One approach is hard-thresholding. Specifically, we choose a clip radius C. if the sanitized location falls within the circle of radius C centered at the original location, then it is a correct positioning. Certainly, the smaller C is, the harder it is to meet the criterion, but the more meaningful "correct" is. Since each location on a trajectory is perturbed independently via the polar Laplace mechanism, with the hard-thresholding rule, the probability of correctly identifying a location can be determined analytically, which is p = F (C; 2, /n), where n is the number of recorded positions on a GPS trajectory and F is the CDF of gamma(2, /n). The number of correctly identified positions m given p follows a binomial distribution m ? Binom(n, p). As for the distribution of CPD l, we can leverage Binom(n, p) to express p(l) analytically when n is small, but p(l) for 1 ? l < n ? k with small k ? 0 becomes less tractable as n increases considering that a trajectory may contain multiple location strings of different l. For example, a GPS trace with n = 10 records may have 2 occurrences of 1 = 1, 1 occurrence of l = 2, and 1 occurrence of l = 3. When the analytical work becomes difficult, we may resort to Monte Carlo (MC) simulations to calculate p(l), as presented in Algorithm 2. Though the algorithm is presented with the hardthresholding rule to define correct positioning, the steps are applicable to other ways of defining correct positioning by updating line 4 of the algorithm. n  We conduct four experiments to investigate empirically the impact of GI sanitization of GPS records on the utility of TPU. Each experiment examines a different road network Algorithm 2: Calculation of CPD p(l) input : K GPS trajectories and their sanitized counterparts with n records per trajectory; clip radius C output: n (l) scenario. We are interested in TPU on a pre-specified target route in each experiment. Besides the PP-TPU and utility analysis, we also examine the adversary error in learning individual trajectories using TD and CPD. In Experiments 1, the simulated road network contains a single road. In Experiments 2, the simulated road network contains three roughly parallel roads, and of them is the target route. In Experiment 3, the road network contains a large roundabout in the town of Creteil in France (Fig  4(a) ), and the target route AB is about 1.5 kilometers long around the roundabout. In Experiment 4, we examine the San Francisco Bay Area (Fig 4(b) ) and the target road AB is about 50 kilometers long. In terms of the GPS trajectory data, the data in Experiment 1 (2,000 travel trajectories) and Experiment 2 (3,000 travel trajectories with 1,000 per road) are simulated as follows. We first simulated speeds from the inverse Weibull distribution with mean µ = 24 meter per second and variance ó 2 = 8 (the values are chosen as is to mimic the real-world traffic speed distributions). For each of the simulated speeds, 10 location records were generated at a fixed timestamp of every ô = 20 seconds, leading to travel trajectories of different length, depending on the speed. The vehicular mobility trace data in Experiment 3 are downloadable from [42] and contains 857,136 sets of location coordinates per second from around 5102 trips in the roundabout area from the morning rush hour (7 to 9 AM), simulated based on real data. The dataset in Experiment 4 contains real mobility traces of taxi cabs and is downloadable from [43] . The raw data contains the GPS coordinates of approximately 500 taxis over 30 days. For this experiment, we used a subset of 30,900 location-time GPS records over the morning rush hours (8 to 9 AM) from 500+ car trips. The simulated GPS records were sanitized via the planar Laplace mechanism and projected into the road map in each experiment using the shortest path algorithm. Since Experiment 1 has a single road, the mappings of all the GPS coordinates land on the target route; in the other 3 experiments, a GPS record can land anywhere on the road network per the shorted path algorithm employed. We set the maximum number of GPS records at 10 per trajectory. Specifically, if a traveller had ? 10 records, we used all of them; if a traveller had > 10 records, we randomly sampled 10 records or had 10 records spaced equally over the trajectory if there were enough records to allow that. For the GI sanitization, we set the per-location per-meter privacy loss at 0.005, 0.01, 0.03, 0.05 and 0.08 in all 4 experiments. Since the maximum of GPS records is 10, the total privacy cost for releasing a trajectory is ? 0.05, 0.1, 0.3, 0.5, 0.8, respectively. The PP-TPU analysis was then conducted via algorithm 1 in each experiment. ample. The original GPS records from the traveller in the leftmost plot are all mapped onto the target road. Though each sanitized GPS location deviates from the original, the shorted path mapping algorithm still projects all of them onto the target road, which are used for the subsequent PP-TPU analysis. For the middle traveller, all the original GPS records of the traveller are mapped onto the target road, but 2 out of 10 of the sanitized consecutive GPS records are not and the 8 on-target mapped records forms 2 location strings of l = 4 and l = 2, respectively and are used for the subsequent of the PP-TPU analysis. For the rightmost traveller, 3 out of 10 sanitized GPS records are mapped onto the target road and they are not consecutive, so this traveller does not contribute toward the PP-TPU in this experiment. In summary, among the 3 trajectories, the first two belong to U, bu not the third one. Fig 6, we also performed the weighted TPU analysis in Experiment 2, and the results are presented in Fig 7. A similar overall trend in the accuracy of the TPU analysis across is observed as in the nonweighted version. The weighting also seems to polarize the PP-TPU accuracy in that the CDF curves at ? 0. 7 : Weighted PP-TPU analysis in Experiment 2 It is practically important to understand the relationship among the per-trajectory privacy budget , the number of travel trajectories K to be collected for PP-TPU, and the accuracy of PP-TPU. This information can be used to help determine how many users' data need to be collected to control the relative error in TPU below a certain threshold for a given , especially for real-time TPU as K varies by weather, car accident, periods of the day, etc. Fig 8 presents the relationship between K, , and the relative error in travel time, defined as the normalized l 1 deviance of the sanitized travel time from the original travel time over K trajectories, based on the data from Experiment 2. As expected, as K increases or per trajectory goes down, the error decreases. For ? 0.3, the error can be controlled below 5% for K as small as 100. Similar relationships can be obtained from the other three experiments.  We examined the adversary error via the proposed TD and CPD p(l) in Sec 3.3. For demonstration purposes, we present the results in Experiment 2 only; similar measures can be obtained from the other three experiments. Table 3 shows the expected distance between the sanitized trajectories and the original trajectory calculated via Eq (13) for per-trajectory privacy budget . As expected, the smaller is, the larger the distance is. The utility analysis in Sec 4.3 suggests that satisfactory accuracy can be achieved at = 0.3 for the PP-TPU analysis. Per Table 3 , the adversary error measured by the TD at = 0.3 is 447 meters across the 10 records per trajectory, which would be regarded as large. Taken together, we may claim that a good trade-off between the TPU utility and privacy protection can be achieved at = 0.3. 9 presents the probability distributions of CPD l and correctly identified positions m (whether consecutive or not) for three different clip radius C (20, 40, and 80 meters) when the number of records per trajectory n = 10 for the same set of per trajectory as examined in all 4 experiments. As expected, as C increases (the criterion for claiming correct positioning loosens) or as per-trajectory increases, the adversary's accuracy for correctly identifying more positions and more consecutive positions increase. In the case of C = 80 meters -a rather relaxed criterion for correct identification, the probability of identifying 10 positions out of 10 is > 80%. The probability decreases to ? 10% for C = 40 meters and ? 0% for C = 20 meters. The plots also illustrate the differences between CPD l and the number of correctly identified locations m. For example, for C = 20, Pr(l = 6) is close to 0%, but Pr(m = 6) is ? 20%, regardless of whether the 6 positions are consecutive or not.  This paper addresses privacy-preserving TPU analyses. We adopt the notation of GI to protect individual spatialtemporal records collected via the GPS, and any subsequent analysis based on it. The proposed PP-TPU procedure can be adopted by service providers (e.g., mobile phone companies, GPS navigator apps) at the GPS data collection stage. We also proposed the concepts of total distance and consecutive positioning degree to assess the adversary error based on released GPS trajectory records, and defined the usefulness concept and different types of deviations in distance measures based on sanitized GPS records. We provided analytical and empirical utility analysis for sanitized locations, distances, and TPU analysis. Our study suggests it is feasible to employ the GI concept to collect and release GPS information for TPU analysis while guaranteeing location privacy for the individuals who contribute their GPS data. Our future work will look into incorporating the dependency among the location points on the same travel trajectory and better utilizing the public road network maps to develop new randomisation mechanisms of better utility without comprising privacy. 